# Basic info
replicaCount: 1
secretsRef: "__REQUIRED__"
image:
  repository: registry.hub.docker.com/datamountaineer/kafka-connect-rethink
  tag: 0.4.0
  pullPolicy: IfNotPresent

# Resource management
resources:
  limits:
    memory: 512Mi
  requests:
    memory: 256Mi
javaHeap: 256M

# Monitoring
monitoring:
  pipeline: "__REQUIRED__"
  enabled: true
  port: 9102
  path: "/metrics"

# SSL/TLS options can be enabled, some connectors provide SSL support, others the newer TLS
# Set the corresponding value type to true. For SSL persistent volumes or hostPaths will be
# mounted under /connector-extra-config. Set the connectors ssl/tls option paths to be use this
# TLS is done via Secrets, create a secret for containing the certificates (base64 encoded) and
# create a secret for them, adding the name of the secret to the `secretsRef` other wise if using
# Eneco's Landscaper it will do this for you.

# SSL mount path on hosts, should be the base path of any ssl keystore/truststore paths
ssl:
  progressEnabled: true
  # Path to the directory on the hosts
  path: /ssl

  # If persistent volumes should be used for ssl keystore/truststore paths
  persistentVolumes:
    enabled: false
    existingClaim:

# TLS, for those connectors supporting TLS certificates rather than ssl key/truststores
# contents for mount take from config map
tls:
  enabled: true

# lenses 
lensesUser: ""

# Connect values
clusterName: "__REQUIRED__"
bootstrapServers: kafka:9092
schemaRegistryURL: "http://schema-registry:8081"
restPort: 8083
logLevel: INFO
keyConverter: "io.confluent.connect.avro.AvroConverter"
valueConveter: "io.confluent.connect.avro.AvroConverter"

javaHeap: "256M"

## Avro schemas, for those connectors, MQTT and JMS source that support Avro converters we
## need the schemas, so we'll mount as a ConfigMap. Set the key value pairs, filename and data
## matching the value option avroSchema. Key is the file name, value is the avro schema contents
#avroSchemaFiles:
#  schema_file_name:  ""

# connectorClass class name of the connector
connectorClass: "com.datamountaineer.streamreactor.connect.rethink.source.ReThinkSourceConnector"

# applicationId name of the connector
applicationId: "__REQUIRED__"

#maxTasks The number of tasks to spawn
maxTasks: 1

# port Client port of rethink server to connect to. type: INT importance: MEDIUM
port: 28015

# lingerMs The number of milliseconds to wait before flushing the received messages to Kafka. The records willbe flushed if the batch size is reached before the linger period has expired. type: LONG importance: MEDIUM
lingerMs: 5000

# rethinkUsername The user name to connect to rethink with. type: STRING importance: MEDIUM
rethinkUsername: 

# rethinkCertFile Certificate file to use for secure TLS connection to the rethinkdb servers. Cannot be used with username/password. type: STRING importance: MEDIUM
rethinkCertFile: 

# password The password for the user. type: PASSWORD importance: MEDIUM
password: "__REQUIRED__"

# db The reThink database to read from. type: STRING importance: HIGH
db: connect_rethink_sink

# batchSize The number of records to drain from the internal queue on each poll. type: INT importance: MEDIUM
batchSize: 1000

# host Rethink server host. type: STRING importance: HIGH
host: localhost

# enabled Enables the output for how many records have been processed type: BOOLEAN importance: MEDIUM
progressEnabled: true

# rethinkAuthKey The authorization key to use in combination with the certificate file. type: PASSWORD importance: MEDIUM
rethinkAuthKey: "__REQUIRED__"

# kcql The KCQL expression for the connector. type: STRING importance: HIGH
kcql: "__REQUIRED__"

