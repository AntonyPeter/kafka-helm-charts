# Basic info
replicaCount: 1
# secretsRef The secret holding any passwords
secretsRef: "__REQUIRED__"
image:
  repository: registry.hub.docker.com/datamountaineer/kafka-connect-pulsar
  tag: 1.0.1
  pullPolicy: IfNotPresent

# Resource management
resources:
  limits:
    memory: 512Mi
  requests:
    memory: 256Mi

# javaHeap options    
javaHeap: 256M

# Monitoring
monitoring:
  pipeline: "__REQUIRED__"
  enabled: true
  port: 9102
  path: "/metrics"

# lenses 
lensesUser: ""

# kafka ssl
# The key and truststores base64 encoded contents
# and added to the kafka secret and mounted into /etc/landoop/kafka-security
kafka:
  securityProtocol:
  ssl:
    enabled: false
    trustStoreFileData:
    trustStorePassword:
    keyStoreFileData:
    keyStorePassword:
  sasl:
    enabled: false
    # keyTabData is the base64 enecode contents kerberos keytable is using kerberos
    keyTabData:    
    # jaasFileData is the base64 encoded contents of the kafka jaas file
    jaasFileData: 
    #GSSAP, SCRAM or PLAIN
    mechanism: 

# Connect values

# clusterName The connect cluster name. This is the consumer group id for the backing topics
clusterName: "__REQUIRED__"

# bootstrapServers A comma separated list of the kafka brokers
bootstrapServers: kafka:9092

# schemaRegistryURL A comman separated list of the Schema registry URL
schemaRegistryURL: "http://schema-registry:8081"

# restPort The rest port of Connect
restPort: 8083

# logLevel The log4j level
logLevel: INFO

# keyConverter The key converter to/from Connects struct
keyConverter: "io.confluent.connect.avro.AvroConverter"

# valueConverter The key converter to/from Connects struct
valueConveter: "io.confluent.connect.avro.AvroConverter"

# connectorClass class name of the connector
connectorClass: "com.datamountaineer.streamreactor.connect.pulsar.source.PulsarSourceConnector"

# applicationId name of the connector
applicationId: "__REQUIRED__"

# maxTasks The number of tasks to spawn
tasksMax: "__REQUIRED__"

# kcql The kcql command to extract and load data from pulsar to Kafka
kcql: "__REQUIRED__"

# hosts Contains the Pulsar connection end points
hosts: "__REQUIRED__"

# converterThrowOnError If set to false the conversion exception will be swallowed and everything carries on BUT the message is lost!!; true will throw the exception.Default is false
converterThrowOnError: false

# converterAvroSchemas If the AvroConverter is used you need to provide an avro Schema to be able to read and translate the raw bytes to an avro record. The format is $PULSAR_TOPIC=$PATH_TO_AVRO_SCHEMA_FILE
converterAvroSchemas: ""

# pollingTimeout Provides the timeout to poll incoming messages
pollingTimeout: 1000

# sslEnabled enabled tls
tlsEnabled: false

# tlsCaCert provides the data (base64 encoded) for the CA certificate file (PEM format) to use with the Pulsar connection which is mounted via the secret
tlsCaCert: 

#tlsCert provides the data (base64 encoded) for the certificate file (PEM format) to use with the Pulsar connection which is mounted via the secret
tlsCert:

# tlsKey certificate private data (base64 encoded) (PEM format) which is mount via the secret
tlsKey:

# errorPolicy Specifies the action to be taken if an error occurs while inserting the data.
# There are two available options:
# NOOP - the error is swallowed
# THROW - the error is allowed to propagate.
# RETRY - The exception causes the Connect framework to retry the message. The number of retries is based on
# The error will be logged automatically type: STRING importance: HIGH
errorPolicy: THROW

# retryInterval The time in milliseconds between retries. type: INT importance: MEDIUM
retryInterval: 60000

# maxRetries The maximum number of times to try the write again. type: INT importance: MEDIUM
maxRetries: 20

# enabled Enables the output for how many records have been processed type: BOOLEAN importance: MEDIUM
progressEnabled: true