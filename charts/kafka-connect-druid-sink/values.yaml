# Basic info
replicaCount: 1

image:
  repository: registry.hub.docker.com/datamountaineer/kafka-connect-druid
  tag: 1.0.1
  pullPolicy: IfNotPresent

# Resource management
resources:
  limits:
    memory: 512Mi
  requests:
    memory: 256Mi

# Monitoring
monitoring:
  pipeline: "__REQUIRED__"
  enabled: true
  port: 9102
  path: "/metrics"

# lenses 
lensesUser: ""

# Connect values
#javaHeap option
javaHeap: "256M"

# clusterName The connect cluster name. This is the consumer group id for the backing topics
clusterName: "__REQUIRED__"

# bootstrapServers A comma separated list of the kafka brokers
bootstrapServers: kafka:9092

# schemaRegistryURL A comman separated list of the Schema registry URL
schemaRegistryURL: "http://schema-registry:8081"

# restPort The rest port of Connect
restPort: 8083

# logLevel The log4j level
logLevel: INFO

# keyConverter The key converter to/from Connects struct
keyConverter: "io.confluent.connect.avro.AvroConverter"

# valueConverter The key converter to/from Connects struct
valueConveter: "io.confluent.connect.avro.AvroConverter"

# applicationId name of the connector
applicationId: "__REQUIRED__"

connectorClass: "com.datamountaineer.streamreactor.connect.druid.DruidSinkConnector"

#maxTasks The number of tasks to spawn
maxTasks: 1

# kcql The KCQL statement to specify field selection from topics and druid datasource targets. type: STRING importance: HIGH
kcql: "__REQUIRED__"

topics: "__REQUIRED__"

# enabled Enables the output for how many records have been processed type: BOOLEAN importance: MEDIUM
progressEnabled: true

# writeTimeout 
# Specifies the number of seconds to wait for the write to Druid to happen.
#      type: INT importance: LOW
writeTimeout: 6000

# dataSource is the druid datasource file which will be mounted as a configmap
dataSource: |-